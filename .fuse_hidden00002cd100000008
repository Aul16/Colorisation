##
# Importation des librairies
import os
import torch
from torch.utils.data import Dataset
from torchvision import datasets, transforms
from torchvision.io import read_image, ImageReadMode
from torchsummary import summary
from torch.utils.data import DataLoader
from torch import nn
import lightning as L

from tqdm import tqdm
import pandas as pd
import matplotlib.pyplot as plt


##
BATCH_SIZE = 64
IMG_SHAPE = (512, 512)


# On crée un dataset custom à partir des images du dossier 'dataset'
class TrainDataset(Dataset):
    def __init__(self, img_csv, img_size):
        self.img_csv = pd.read_csv(img_csv)
        self.transform = transforms.Resize(img_size)

    def __len__(self):
        return len(self.img_csv)

    def __getitem__(self, index):
        img_name = self.img_csv.iloc[index, 0]
        image = [read_image(f"./Train_K/color_BW/{img_name}", ImageReadMode.RGB), read_image(f"./Train_K/color_full/{img_name}", ImageReadMode.RGB)]
        # On reshape les données :

        image = [self.transform(img) for img in image]

        # On normalise les données
        image = [(img - 127.5)/127.5 for img in image]
        return image[0], image[1]


training_data = TrainDataset('./images_Train_K.csv', IMG_SHAPE)

# On charge notre dataset dans un dataloader
x_train = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)


##
for i, (img, gray_img) in enumerate(x_train):
    plt.subplot(3, 3, 3*i+1)
    plt.imshow(img[0].permute(1, 2, 0))
    plt.axis('off')
    plt.subplot(3, 3, 3*i + 2)
    plt.imshow(gray_img[0].permute(1,2,0), cmap="gray")
    plt.axis('off')
    plt.subplot(3, 3, 3*i + 3)
    plt.imshow(gray_img[0].permute(1,2,0), cmap="gray")
    plt.axis('off')
    if i >= 2:
        break
plt.show()


##
class Encoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 64, 3, stride=1, padding=1)
        self.batch1 = nn.BatchNorm2d(64)
        self.conv2 = nn.Conv2d(64, 128, 3, stride=1, padding=1)
        self.batch2 = nn.BatchNorm2d(128)
        self.conv3 = nn.Conv2d(128, 256, 3, stride=1, padding=1)
        self.batch3 = nn.BatchNorm2d(256)
        self.conv4 = nn.Conv2d(256, 512, 3, stride=1, padding=1)
        self.batch4 = nn.BatchNorm2d(512)
        self.conv5 = nn.Conv2d(512, 512, 3, stride=1, padding=1)
        self.batch5 = nn.BatchNorm2d(512)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv1(x)
        out1 = self.batch1(x)
        x = self.relu(out1)
        x = self.conv2(x)
        out2 = self.batch2(x)
        x = self.relu(out2)
        x = self.conv3(x)
        out3 = self.batch3(x)
        x = self.relu(out3)
        x = self.conv4(x)
        out4 = self.batch4(x)
        x = self.relu(out4)
        x = self.conv5(x)
        out5 = self.batch5(x)

        return [out1, out2, out3, out4, out5]


##
class Decoder(nn.Module):
    def __init__(self):
        super().__init__()
        self.convT1 = nn.ConvTranspose2d(512, 512, 3, stride=1, padding=1)
        self.conv1 = nn.Conv2d(1024, 512, 3, stride=1, padding=1)
        self.convT2 = nn.ConvTranspose2d(512, 256, 3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(512, 256, 3, stride=1, padding=1)
        self.convT3 = nn.ConvTranspose2d(256, 128, 3, stride=1, padding=1)
        self.conv3 = nn.Conv2d(256, 128, 3, stride=1, padding=1)
        self.convT4 = nn.ConvTranspose2d(128, 64, 3, stride=1, padding=1)
        self.conv4 = nn.Conv2d(128, 3, 3, stride=1, padding=1)
        self.relu = nn.ReLU()

    def forward(self, *encoder_out):
        x = self.convT1(encoder_out[-1])
        x = self.relu(x)
        x = torch.cat((x, encoder_out[-2]), dim=1)
        x = self.conv1(x)
        x = self.relu(x)

        x = self.convT2(x)
        x = self.relu(x)
        x = torch.cat((x, encoder_out[-3]), dim=1)
        x = self.conv2(x)
        x = self.relu(x)

        x = self.convT3(x)
        x = self.relu(x)
        x = torch.cat((x, encoder_out[-4]), dim=1)
        x = self.conv3(x)
        x = self.relu(x)

        x = self.convT4(x)
        x = self.relu(x)
        x = torch.cat((x, encoder_out[-5]), dim=1)
        x = self.conv4(x)
        x = self.relu(x)

        return x


##
class Unet(L.LightningModule):
    def __init__(self):
        super().__init__()
        self.encoder = Encoder()
        self.decoder = Decoder()
        self.loss = nn.MSELoss()

    def forward(self, x):
        encoder_out = self.encoder(x)
        x = self.decoder(*encoder_out)
        return x

    def training_step(self, batch, batch_idx):
        x, y = batch
        y_hat = self(x)
        loss = self.loss(y_hat, y)
        self.log('train_loss', loss)
        return loss

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)
        return optimizer


##
model = Unet()
trainer = L.Trainer(max_epochs=10)
trainer.fit(model, x_train)

##


##

